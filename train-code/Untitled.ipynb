{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os, time, shutil\n",
    "\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.utils import makedirs\n",
    "from gluoncv.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "\n",
    "classes = 2\n",
    "\n",
    "epochs = 40\n",
    "lr = 0.001\n",
    "per_device_batch_size = 128\n",
    "momentum = 0.9\n",
    "wd = 0.0001\n",
    "\n",
    "lr_factor = 0.75\n",
    "lr_steps = [10, 20, 30, np.inf]\n",
    "\n",
    "num_gpus = 1\n",
    "num_workers = 8\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "batch_size = per_device_batch_size * max(num_gpus, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    transforms.RandomColorJitter(brightness=jitter_param, contrast=jitter_param,\n",
    "                                 saturation=jitter_param),\n",
    "    transforms.RandomLighting(lighting_param),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader\n",
    "\n",
    "from mxnet.gluon.data.vision import ImageFolderDataset\n",
    "import cv2\n",
    "\n",
    "class BKData(ImageFolderDataset):\n",
    "    def __init__(self, *arg1, **arg2):\n",
    "        super(BKData,self).__init__(*arg1,**arg2)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        use cv2 backend\n",
    "        '''\n",
    "        img  = cv2.imread(self.items[idx][0])\n",
    "        img  = nd.array( img[:,:,:3]).astype(np.uint8)\n",
    "        label = self.items[idx][1]\n",
    "        if self._transform is not None:\n",
    "            return self._transform(img, label)\n",
    "        return img, label\n",
    "\n",
    "path = './images'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    BKData(train_path).transform_first(transform_train),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_data = gluon.data.DataLoader(\n",
    "    BKData(val_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    BKData(test_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and trainer\n",
    "\n",
    "model_name = 'ResNet50_v2'\n",
    "finetune_net = get_model(model_name, pretrained=True)\n",
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
    "# finetune_net.cast('float16')\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()\n",
    "\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                        'learning_rate': lr, 'momentum': momentum, 'wd': wd})\n",
    "metric = mx.metric.Accuracy()\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test\n",
    "\n",
    "def test(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train-acc: 0.861, loss: 0.416 | Val-acc: 0.886 | time: 69.4\n",
      "[Epoch 1] Train-acc: 0.892, loss: 0.292 | Val-acc: 0.894 | time: 58.9\n",
      "[Epoch 2] Train-acc: 0.899, loss: 0.269 | Val-acc: 0.897 | time: 58.7\n",
      "[Epoch 3] Train-acc: 0.906, loss: 0.243 | Val-acc: 0.906 | time: 59.7\n",
      "[Epoch 4] Train-acc: 0.914, loss: 0.230 | Val-acc: 0.913 | time: 59.0\n",
      "[Epoch 5] Train-acc: 0.918, loss: 0.215 | Val-acc: 0.913 | time: 59.5\n",
      "[Epoch 6] Train-acc: 0.922, loss: 0.201 | Val-acc: 0.912 | time: 58.8\n",
      "[Epoch 7] Train-acc: 0.928, loss: 0.192 | Val-acc: 0.909 | time: 58.6\n",
      "[Epoch 8] Train-acc: 0.929, loss: 0.183 | Val-acc: 0.915 | time: 58.2\n",
      "[Epoch 9] Train-acc: 0.935, loss: 0.179 | Val-acc: 0.911 | time: 57.8\n",
      "[Epoch 10] Train-acc: 0.935, loss: 0.168 | Val-acc: 0.910 | time: 58.9\n",
      "[Epoch 11] Train-acc: 0.939, loss: 0.157 | Val-acc: 0.913 | time: 59.2\n",
      "[Epoch 12] Train-acc: 0.943, loss: 0.151 | Val-acc: 0.912 | time: 59.5\n",
      "[Epoch 13] Train-acc: 0.941, loss: 0.156 | Val-acc: 0.916 | time: 59.2\n",
      "[Epoch 14] Train-acc: 0.947, loss: 0.144 | Val-acc: 0.913 | time: 59.2\n",
      "[Epoch 15] Train-acc: 0.949, loss: 0.136 | Val-acc: 0.915 | time: 58.9\n",
      "[Epoch 16] Train-acc: 0.950, loss: 0.141 | Val-acc: 0.914 | time: 58.8\n",
      "[Epoch 17] Train-acc: 0.952, loss: 0.128 | Val-acc: 0.917 | time: 59.4\n",
      "[Epoch 18] Train-acc: 0.953, loss: 0.130 | Val-acc: 0.913 | time: 59.9\n",
      "[Epoch 19] Train-acc: 0.953, loss: 0.128 | Val-acc: 0.913 | time: 58.4\n",
      "[Epoch 20] Train-acc: 0.954, loss: 0.117 | Val-acc: 0.915 | time: 59.6\n",
      "[Epoch 21] Train-acc: 0.953, loss: 0.120 | Val-acc: 0.914 | time: 59.2\n",
      "[Epoch 22] Train-acc: 0.960, loss: 0.112 | Val-acc: 0.915 | time: 58.8\n",
      "[Epoch 23] Train-acc: 0.960, loss: 0.110 | Val-acc: 0.918 | time: 58.8\n",
      "[Epoch 24] Train-acc: 0.958, loss: 0.111 | Val-acc: 0.922 | time: 58.5\n",
      "[Epoch 25] Train-acc: 0.959, loss: 0.108 | Val-acc: 0.919 | time: 59.3\n",
      "[Epoch 26] Train-acc: 0.961, loss: 0.103 | Val-acc: 0.915 | time: 58.3\n",
      "[Epoch 27] Train-acc: 0.961, loss: 0.100 | Val-acc: 0.915 | time: 59.0\n",
      "[Epoch 28] Train-acc: 0.962, loss: 0.103 | Val-acc: 0.920 | time: 58.3\n",
      "[Epoch 29] Train-acc: 0.962, loss: 0.100 | Val-acc: 0.918 | time: 59.1\n",
      "[Epoch 30] Train-acc: 0.966, loss: 0.092 | Val-acc: 0.919 | time: 59.1\n",
      "[Epoch 31] Train-acc: 0.963, loss: 0.098 | Val-acc: 0.920 | time: 58.3\n",
      "[Epoch 32] Train-acc: 0.965, loss: 0.094 | Val-acc: 0.920 | time: 58.4\n",
      "[Epoch 33] Train-acc: 0.967, loss: 0.087 | Val-acc: 0.920 | time: 58.7\n",
      "[Epoch 34] Train-acc: 0.971, loss: 0.083 | Val-acc: 0.920 | time: 59.1\n",
      "[Epoch 35] Train-acc: 0.969, loss: 0.087 | Val-acc: 0.921 | time: 57.6\n",
      "[Epoch 36] Train-acc: 0.968, loss: 0.085 | Val-acc: 0.920 | time: 59.0\n",
      "[Epoch 37] Train-acc: 0.971, loss: 0.082 | Val-acc: 0.922 | time: 59.2\n",
      "[Epoch 38] Train-acc: 0.975, loss: 0.076 | Val-acc: 0.920 | time: 59.3\n",
      "[Epoch 39] Train-acc: 0.972, loss: 0.077 | Val-acc: 0.919 | time: 59.7\n",
      "Training Duration is 2367.4195368289948\n",
      "[Finished] Test-acc: 0.927\n"
     ]
    }
   ],
   "source": [
    "# start train\n",
    "\n",
    "lr_counter = 0\n",
    "num_batch = len(train_data)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == lr_steps[lr_counter]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_factor)\n",
    "        lr_counter += 1\n",
    "\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    metric.reset()\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        with ag.record():\n",
    "            outputs = [finetune_net(X) for X in data]\n",
    "            loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
    "\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    _, train_acc = metric.get()\n",
    "    train_loss /= num_batch\n",
    "\n",
    "    _, val_acc = test(finetune_net, val_data, ctx)\n",
    "\n",
    "    print('[Epoch %d] Train-acc: %.3f, loss: %.3f | Val-acc: %.3f | time: %.1f' %\n",
    "             (epoch, train_acc, train_loss, val_acc, time.time() - tic))\n",
    "\n",
    "print(\"Training Duration is {}\".format(time.time() - t0))\n",
    "_, test_acc = test(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
