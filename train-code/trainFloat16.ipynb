{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os, time, shutil\n",
    "\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.utils import makedirs\n",
    "from gluoncv.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割一下数据集~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'terrorNum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5b45dacd2fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimglist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./classified-images/normal/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./classified-images/terror/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainPlusValNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterrorNum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnormalNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;31m# 8117\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtestNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterrorNum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnormalNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.3\u001b[0m \u001b[0;31m# 3479\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'terrorNum' is not defined"
     ]
    }
   ],
   "source": [
    "imglist = os.listdir(\"./classified-images/normal/\") + os.listdir(\"./classified-images/terror/\")\n",
    "\n",
    "trainPlusValNum = (terrorNum + normalNum)*0.7 # 8117\n",
    "testNum = (terrorNum + normalNum)*0.3 # 3479\n",
    "\n",
    "normalNum = 1335\n",
    "terrorNum = 10261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 2\n",
    "\n",
    "epochs = 40\n",
    "lr = 0.001\n",
    "per_device_batch_size = 256\n",
    "momentum = 0.9\n",
    "wd = 0.0001\n",
    "\n",
    "lr_factor = 0.75\n",
    "lr_steps = [10, 20, 30, np.inf]\n",
    "\n",
    "num_gpus = 1\n",
    "num_workers = 8\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "batch_size = per_device_batch_size * max(num_gpus, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    transforms.RandomColorJitter(brightness=jitter_param, contrast=jitter_param,\n",
    "                                 saturation=jitter_param),\n",
    "    transforms.RandomLighting(lighting_param),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision import ImageFolderDataset\n",
    "import cv2\n",
    "\n",
    "class BKData(ImageFolderDataset):\n",
    "    def __init__(self, *arg1, **arg2):\n",
    "        super(BKData,self).__init__(*arg1,**arg2)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        use cv2 backend\n",
    "        '''\n",
    "        img  = cv2.imread(self.items[idx][0])\n",
    "        img  = nd.array( img[:,:,:3]).astype(np.uint8)\n",
    "        label = self.items[idx][1]\n",
    "        if self._transform is not None:\n",
    "            return self._transform(img, label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './images'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    BKData(train_path).transform_first(transform_train),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_data = gluon.data.DataLoader(\n",
    "    BKData(val_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    BKData(test_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ResNet50_v2'\n",
    "finetune_net = get_model(model_name, pretrained=True)\n",
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
    "# finetune_net.cast('float16')\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()\n",
    "\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                        'learning_rate': lr, 'momentum': momentum, 'wd': wd})\n",
    "metric = mx.metric.Accuracy()\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                        'learning_rate': lr, 'momentum': momentum, 'wd': wd,\n",
    "                        'multi_precision': True})\n",
    "\n",
    "\n",
    "\n",
    "metric = mx.metric.Accuracy()\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0].astype(\"float16\", copy=False), ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1].astype(\"float16\", copy=False), ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        \n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train-acc: 0.864, loss: 0.415 | Val-acc: 0.885 | time: 71.8\n",
      "[Epoch 1] Train-acc: 0.886, loss: 0.339 | Val-acc: 0.887 | time: 63.9\n",
      "[Epoch 2] Train-acc: 0.888, loss: 0.306 | Val-acc: 0.891 | time: 64.8\n",
      "[Epoch 3] Train-acc: 0.894, loss: 0.279 | Val-acc: 0.892 | time: 63.5\n",
      "[Epoch 4] Train-acc: 0.897, loss: 0.270 | Val-acc: 0.894 | time: 63.4\n",
      "[Epoch 5] Train-acc: 0.901, loss: 0.250 | Val-acc: 0.902 | time: 63.5\n",
      "[Epoch 6] Train-acc: 0.906, loss: 0.245 | Val-acc: 0.901 | time: 63.3\n",
      "[Epoch 7] Train-acc: 0.908, loss: 0.235 | Val-acc: 0.902 | time: 61.4\n",
      "[Epoch 8] Train-acc: 0.911, loss: 0.228 | Val-acc: 0.905 | time: 63.5\n",
      "[Epoch 9] Train-acc: 0.917, loss: 0.217 | Val-acc: 0.907 | time: 62.4\n",
      "[Epoch 10] Train-acc: 0.921, loss: 0.210 | Val-acc: 0.906 | time: 63.7\n",
      "[Epoch 11] Train-acc: 0.924, loss: 0.200 | Val-acc: 0.906 | time: 62.9\n",
      "[Epoch 12] Train-acc: 0.921, loss: 0.204 | Val-acc: 0.909 | time: 63.5\n",
      "[Epoch 13] Train-acc: 0.926, loss: 0.194 | Val-acc: 0.909 | time: 64.4\n",
      "[Epoch 14] Train-acc: 0.928, loss: 0.188 | Val-acc: 0.910 | time: 64.7\n",
      "[Epoch 15] Train-acc: 0.923, loss: 0.194 | Val-acc: 0.910 | time: 61.7\n",
      "[Epoch 16] Train-acc: 0.926, loss: 0.181 | Val-acc: 0.911 | time: 60.8\n",
      "[Epoch 17] Train-acc: 0.932, loss: 0.178 | Val-acc: 0.910 | time: 62.4\n",
      "[Epoch 18] Train-acc: 0.932, loss: 0.180 | Val-acc: 0.909 | time: 61.7\n",
      "[Epoch 19] Train-acc: 0.938, loss: 0.166 | Val-acc: 0.909 | time: 63.9\n",
      "[Epoch 20] Train-acc: 0.933, loss: 0.172 | Val-acc: 0.908 | time: 64.5\n",
      "[Epoch 21] Train-acc: 0.939, loss: 0.165 | Val-acc: 0.910 | time: 65.1\n",
      "[Epoch 22] Train-acc: 0.938, loss: 0.165 | Val-acc: 0.911 | time: 65.2\n",
      "[Epoch 23] Train-acc: 0.942, loss: 0.155 | Val-acc: 0.910 | time: 65.8\n",
      "[Epoch 24] Train-acc: 0.940, loss: 0.170 | Val-acc: 0.912 | time: 65.3\n",
      "[Epoch 25] Train-acc: 0.940, loss: 0.157 | Val-acc: 0.911 | time: 64.1\n",
      "[Epoch 26] Train-acc: 0.941, loss: 0.155 | Val-acc: 0.913 | time: 65.2\n",
      "[Epoch 27] Train-acc: 0.941, loss: 0.160 | Val-acc: 0.913 | time: 64.7\n",
      "[Epoch 28] Train-acc: 0.945, loss: 0.156 | Val-acc: 0.914 | time: 62.2\n",
      "[Epoch 29] Train-acc: 0.946, loss: 0.145 | Val-acc: 0.913 | time: 63.9\n",
      "[Epoch 30] Train-acc: 0.942, loss: 0.145 | Val-acc: 0.914 | time: 66.5\n",
      "[Epoch 31] Train-acc: 0.943, loss: 0.149 | Val-acc: 0.913 | time: 173.4\n",
      "[Epoch 32] Train-acc: 0.948, loss: 0.140 | Val-acc: 0.914 | time: 106.0\n",
      "[Epoch 33] Train-acc: 0.949, loss: 0.138 | Val-acc: 0.914 | time: 64.4\n",
      "[Epoch 34] Train-acc: 0.947, loss: 0.140 | Val-acc: 0.915 | time: 65.1\n",
      "[Epoch 35] Train-acc: 0.952, loss: 0.131 | Val-acc: 0.915 | time: 65.4\n",
      "[Epoch 36] Train-acc: 0.951, loss: 0.133 | Val-acc: 0.913 | time: 66.7\n",
      "[Epoch 37] Train-acc: 0.949, loss: 0.132 | Val-acc: 0.915 | time: 63.4\n",
      "[Epoch 38] Train-acc: 0.954, loss: 0.127 | Val-acc: 0.917 | time: 64.8\n",
      "[Epoch 39] Train-acc: 0.954, loss: 0.142 | Val-acc: 0.915 | time: 63.5\n",
      "Training Duration is 8.843548059463501\n",
      "[Finished] Test-acc: 0.930\n"
     ]
    }
   ],
   "source": [
    "lr_counter = 0\n",
    "num_batch = len(train_data)\n",
    "\n",
    "time_duration = []\n",
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == lr_steps[lr_counter]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_factor)\n",
    "        lr_counter += 1\n",
    "\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    metric.reset()\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = gluon.utils.split_and_load(batch[0].astype(\"float16\"), ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1].astype(\"float16\"), ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        with ag.record():\n",
    "            t0 = time.time()\n",
    "            outputs = [finetune_net(X) for X in data]\n",
    "            time_duration.append(time.time() - t0)\n",
    "            loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
    "\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    _, train_acc = metric.get()\n",
    "    train_loss /= num_batch\n",
    "\n",
    "    _, val_acc = test(finetune_net, val_data, ctx)\n",
    "\n",
    "    print('[Epoch %d] Train-acc: %.3f, loss: %.3f | Val-acc: %.3f | time: %.1f' %\n",
    "             (epoch, train_acc, train_loss, val_acc, time.time() - tic))\n",
    "\n",
    "print(\"Training Duration is {}\".format(sum(time_duration)))\n",
    "_, test_acc = test(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_net.save_parameters(\"./fp16-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
